# -*- coding: utf-8 -*-
"""Untitled28.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/10aNUGx2lKDjanvHkzOpyiqgoBKFNM1IQ
"""

# Import necessary libraries
import pandas as pd
import numpy as np
from sklearn.model_selection import train_test_split, GridSearchCV, StratifiedKFold, cross_val_score
from sklearn.preprocessing import StandardScaler, LabelEncoder
from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier
from sklearn.metrics import classification_report, confusion_matrix, accuracy_score, roc_auc_score, roc_curve
from imblearn.over_sampling import SMOTE
from xgboost import XGBClassifier

# Load dataset
data = pd.read_csv('/content/healthcare-dataset-stroke-data.csv')
data.drop("id", axis=1, inplace=True)

# Fill missing values
data['bmi'].fillna(data['bmi'].mean(), inplace=True)

# Encoding categorical features and scaling numerical ones
data_encoded = pd.get_dummies(data, drop_first=True)
scaler = StandardScaler()
numeric_columns = ['age', 'avg_glucose_level', 'bmi']  # adjust based on your columns
data_encoded[numeric_columns] = scaler.fit_transform(data_encoded[numeric_columns])

# Separate features and target
X = data_encoded.drop('stroke', axis=1)
y = data_encoded['stroke']

# Handle class imbalance using SMOTE
smote = SMOTE(random_state=42)
X_resampled, y_resampled = smote.fit_resample(X, y)

# Split data
X_train, X_test, y_train, y_test = train_test_split(X_resampled, y_resampled, test_size=0.2, random_state=42)

# Set up cross-validation
cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)

# Initialize models with optimized hyperparameters
models = {
    'RandomForest': RandomForestClassifier(n_estimators=100, max_depth=10, random_state=42),
    'GradientBoosting': GradientBoostingClassifier(n_estimators=100, learning_rate=0.1, max_depth=3, random_state=42),
    'XGBoost': XGBClassifier(use_label_encoder=False, eval_metric='logloss', n_estimators=100, learning_rate=0.1, max_depth=3, random_state=42)
}

# Perform hyperparameter tuning with GridSearchCV
param_grid = {
    'RandomForest': {
        'n_estimators': [100, 200],
        'max_depth': [10, 15, 20]
    },
    'GradientBoosting': {
        'n_estimators': [100, 200],
        'learning_rate': [0.05, 0.1],
        'max_depth': [3, 4]
    },
    'XGBoost': {
        'n_estimators': [100, 200],
        'learning_rate': [0.05, 0.1],
        'max_depth': [3, 5]
    }
}

best_models = {}
for model_name in models:
    grid_search = GridSearchCV(models[model_name], param_grid[model_name], cv=cv, scoring='roc_auc', n_jobs=-1)
    grid_search.fit(X_train, y_train)
    best_models[model_name] = grid_search.best_estimator_

# Evaluate each model on the test set
for name, model in best_models.items():
    y_pred = model.predict(X_test)
    print(f"\n{name} Model Evaluation:")
    print("Confusion Matrix:\n", confusion_matrix(y_test, y_pred))
    print("Classification Report:\n", classification_report(y_test, y_pred))
    print("ROC AUC Score:", roc_auc_score(y_test, y_pred))

# Ensemble Model with Averaging Technique
from sklearn.ensemble import VotingClassifier

# Combine the best models using Voting Classifier
ensemble_model = VotingClassifier(
    estimators=[(name, best_models[name]) for name in best_models.keys()],
    voting='soft'
)
ensemble_model.fit(X_train, y_train)

# Evaluate the ensemble model
y_pred_ensemble = ensemble_model.predict(X_test)
print("\nEnsemble Model Evaluation:")
print("Confusion Matrix:\n", confusion_matrix(y_test, y_pred_ensemble))
print("Classification Report:\n", classification_report(y_test, y_pred_ensemble))
print("ROC AUC Score:", roc_auc_score(y_test, y_pred_ensemble))

import joblib

# Save each best model
for name, model in best_models.items():
    joblib.dump(model, f"{name}_best_model.pkl")
    print(f"{name} model saved as {name}_best_model.pkl")

# Save the ensemble model
joblib.dump(ensemble_model, "ensemble_model.pkl")
print("Ensemble model saved as ensemble_model.pkl")